{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import (InceptionResNetV2, MobileNetV2,\n",
    "                                           ResNet50)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset/download?datasetVersionNumber=2\n",
    "ZIP_URL = \"https://storage.googleapis.com/kaggle-data-sets/615374/1199870/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230420%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230420T192923Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0c4467abd662778a52538888d7649dc42d543d1cdf4a2d2bc7d0edbb93a3787fdaf5f88e345b02038e5053df653a90c6af4a92cf5c28389a171620900a94c86be718201daa99c27598199a83d248946bd429d50dacbeb2179476af88f90acd199d1bbaa09765b8775ed7372eb9f92c7ff8e8df204d9aed057877f9f2e556cb4f2c95c59503f47dd015083aa6356c6629a76ebcc12c05b3cd896239f53316e857252b1ab0d5ff97ed4156dd43f1617b6d0943a63152c4ac02584850c916f1cfec9405dfd717ce868982f6275d8932b70ce01eac7b371e6f4c265d3d8bbfde389fa1ca206957245a0e8d7d2e29621ff6ea2edc4aabc0ef1f646c7083808b3ab032\"\n",
    "ZIP_FILE = \"archive.zip\"\n",
    "CLASSES = (\"covid\", \"normal\")\n",
    "N_CLASSES = len(CLASSES)\n",
    "WEIGHTS_DIR = \"weights\"\n",
    "INPUT_DIR = \"archive\"\n",
    "INPUT_DIR_COVID = os.path.join(INPUT_DIR, \"covid\")\n",
    "INPUT_DIR_NORMAL = os.path.join(INPUT_DIR, \"normal\")\n",
    "OUTPUT_DIR = \"sarscov2-ctscan-dataset\"\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
    "VALIDATION_DIR = os.path.join(OUTPUT_DIR, \"validation\")\n",
    "SPLIT_RATIO = 0.8\n",
    "RANDOM_SEED = 12345\n",
    "N_EPOCHS = 30\n",
    "LR = 0.0001\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(ZIP_URL) as response:\n",
    "    with open(ZIP_FILE, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "    with ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
    "        zip_ref.extractall(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the folders\n",
    "os.rename(os.path.join(INPUT_DIR, \"COVID\"), INPUT_DIR_COVID)\n",
    "os.rename(os.path.join(INPUT_DIR, \"non-COVID\"), INPUT_DIR_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las carpetas para el conjunto de datos de entrenamiento y validación\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    for d in {VALIDATION_DIR, TRAIN_DIR}:\n",
    "        for c in CLASSES:\n",
    "            os.makedirs(os.path.join(d, c))\n",
    "if not os.path.exists(WEIGHTS_DIR):\n",
    "        os.makedirs(WEIGHTS_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de imágenes de entrada\n",
    "image_filenames_covid = os.listdir(INPUT_DIR_COVID)\n",
    "image_filenames_normal = os.listdir(INPUT_DIR_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar la lista de imágenes aleatoriamente\n",
    "random.seed(RANDOM_SEED)\n",
    "random.shuffle(image_filenames_covid)\n",
    "random.shuffle(image_filenames_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_set(input_dir, image_filenames, label:str= \"covid\"):\n",
    "    # Dividir la lista de imágenes en los conjuntos de entrenamiento y validación\n",
    "    split_index = int(len(image_filenames) * SPLIT_RATIO)\n",
    "    train_filenames = image_filenames[:split_index]\n",
    "    validation_filenames = image_filenames[split_index:]\n",
    "    # Copiar las imágenes de entrenamiento\n",
    "    for filename in train_filenames:\n",
    "        source_path = os.path.join(input_dir, filename)\n",
    "        print(source_path)\n",
    "        destination_path = os.path.join(TRAIN_DIR, label, filename)\n",
    "        print(destination_path)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    # Copiar las imágenes de validación\n",
    "    for filename in validation_filenames:\n",
    "        source_path = os.path.join(input_dir, filename)\n",
    "        destination_path = os.path.join(VALIDATION_DIR, label, filename)\n",
    "        shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_set(input_dir=INPUT_DIR_COVID,\n",
    "               image_filenames=image_filenames_covid,\n",
    "               label=\"covid\")\n",
    "split_data_set(input_dir=INPUT_DIR_NORMAL,\n",
    "               image_filenames=image_filenames_normal,\n",
    "               label=\"normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in [TRAIN_DIR, VALIDATION_DIR]:\n",
    "    for c in CLASSES:\n",
    "        path_1 = os.path.join(d, c)\n",
    "        for filename in os.listdir(path_1):\n",
    "            path_2 = os.path.join(path_1, filename)\n",
    "            with Image.open(path_2) as im:\n",
    "                im = im.convert('L')\n",
    "                im = im.resize(IMG_SIZE)\n",
    "                im.save(path_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=10\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1984 images belonging to 2 classes.\n",
      "Found 497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE, #(299, 299),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=IMG_SIZE, #(299, 299),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(base_model, fc:int = 1024, drop_out: float = 0.2):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(fc, activation='relu')(x)\n",
    "    x = Dropout(drop_out)(x)\n",
    "    predictions = Dense(N_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_resnet50 = ResNet50 (include_top=False,\n",
    "                                         weights='imagenet',\n",
    "                                         input_shape=IMG_SIZE+(3,),\n",
    "                                         )\n",
    "model_resnet50 = custom_model(base_model_resnet50)\n",
    "model_resnet50.compile(optimizer=Adam(learning_rate=LR),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy']\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_mobilenetv2 = MobileNetV2(include_top=False,\n",
    "                                     weights='imagenet',\n",
    "                                     input_shape=IMG_SIZE+(3,),\n",
    "                                     )\n",
    "model_mobilenetv2 = custom_model(base_model_mobilenetv2)\n",
    "model_mobilenetv2.compile(optimizer=Adam(learning_rate=LR),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy']\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_inception_resnet_v2 = InceptionResNetV2(include_top=False,\n",
    "                                                   weights='imagenet',\n",
    "                                                   input_shape=IMG_SIZE+(3,),\n",
    "                                                   )\n",
    "model_inception_resnet_v2 = custom_model(base_model_inception_resnet_v2)\n",
    "model_inception_resnet_v2.compile(optimizer=Adam(lr=LR),\n",
    "                                  loss='categorical_crossentropy',\n",
    "                                  metrics=['accuracy']\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "62/62 [==============================] - 58s 869ms/step - loss: 0.7245 - accuracy: 0.5282 - val_loss: 0.6789 - val_accuracy: 0.5553\n",
      "Epoch 2/30\n",
      "62/62 [==============================] - 55s 879ms/step - loss: 0.7090 - accuracy: 0.5494 - val_loss: 0.6828 - val_accuracy: 0.5915\n",
      "Epoch 3/30\n",
      "62/62 [==============================] - 53s 856ms/step - loss: 0.7031 - accuracy: 0.5514 - val_loss: 0.7003 - val_accuracy: 0.5815\n",
      "Epoch 4/30\n",
      "62/62 [==============================] - 54s 861ms/step - loss: 0.6809 - accuracy: 0.5862 - val_loss: 0.6559 - val_accuracy: 0.6378\n",
      "Epoch 5/30\n",
      "62/62 [==============================] - 53s 849ms/step - loss: 0.6667 - accuracy: 0.5968 - val_loss: 0.6427 - val_accuracy: 0.6197\n",
      "Epoch 6/30\n",
      "62/62 [==============================] - 53s 847ms/step - loss: 0.6718 - accuracy: 0.5862 - val_loss: 0.6641 - val_accuracy: 0.6338\n",
      "Epoch 7/30\n",
      "62/62 [==============================] - 52s 843ms/step - loss: 0.6577 - accuracy: 0.6210 - val_loss: 0.6295 - val_accuracy: 0.6539\n",
      "Epoch 8/30\n",
      "62/62 [==============================] - 53s 851ms/step - loss: 0.6448 - accuracy: 0.6265 - val_loss: 0.6315 - val_accuracy: 0.6519\n",
      "Epoch 9/30\n",
      "62/62 [==============================] - 53s 849ms/step - loss: 0.6410 - accuracy: 0.6326 - val_loss: 0.6229 - val_accuracy: 0.6660\n",
      "Epoch 10/30\n",
      "62/62 [==============================] - 53s 845ms/step - loss: 0.6275 - accuracy: 0.6447 - val_loss: 0.6120 - val_accuracy: 0.6700\n",
      "Epoch 11/30\n",
      "62/62 [==============================] - 53s 851ms/step - loss: 0.6207 - accuracy: 0.6462 - val_loss: 0.6298 - val_accuracy: 0.6640\n",
      "Epoch 12/30\n",
      "62/62 [==============================] - 53s 853ms/step - loss: 0.6211 - accuracy: 0.6467 - val_loss: 0.6092 - val_accuracy: 0.6801\n",
      "Epoch 13/30\n",
      "62/62 [==============================] - 53s 849ms/step - loss: 0.6219 - accuracy: 0.6502 - val_loss: 0.6439 - val_accuracy: 0.6358\n",
      "Epoch 14/30\n",
      "62/62 [==============================] - 53s 850ms/step - loss: 0.6178 - accuracy: 0.6573 - val_loss: 0.5905 - val_accuracy: 0.6801\n",
      "Epoch 15/30\n",
      "62/62 [==============================] - 52s 839ms/step - loss: 0.6156 - accuracy: 0.6532 - val_loss: 0.5881 - val_accuracy: 0.6901\n",
      "Epoch 16/30\n",
      "62/62 [==============================] - 53s 855ms/step - loss: 0.6173 - accuracy: 0.6618 - val_loss: 0.5930 - val_accuracy: 0.6982\n",
      "Epoch 17/30\n",
      "62/62 [==============================] - 53s 851ms/step - loss: 0.6036 - accuracy: 0.6709 - val_loss: 0.5836 - val_accuracy: 0.6881\n",
      "Epoch 18/30\n",
      "62/62 [==============================] - 53s 846ms/step - loss: 0.6284 - accuracy: 0.6391 - val_loss: 0.5776 - val_accuracy: 0.6982\n",
      "Epoch 19/30\n",
      "62/62 [==============================] - 53s 859ms/step - loss: 0.5941 - accuracy: 0.6815 - val_loss: 0.5901 - val_accuracy: 0.6942\n",
      "Epoch 20/30\n",
      "62/62 [==============================] - 53s 850ms/step - loss: 0.5888 - accuracy: 0.7031 - val_loss: 0.5696 - val_accuracy: 0.7002\n",
      "Epoch 21/30\n",
      "62/62 [==============================] - 52s 838ms/step - loss: 0.5880 - accuracy: 0.6935 - val_loss: 0.5767 - val_accuracy: 0.7022\n",
      "Epoch 22/30\n",
      "62/62 [==============================] - 53s 856ms/step - loss: 0.5901 - accuracy: 0.6880 - val_loss: 0.5711 - val_accuracy: 0.7163\n",
      "Epoch 23/30\n",
      "62/62 [==============================] - 52s 842ms/step - loss: 0.5802 - accuracy: 0.6885 - val_loss: 0.5791 - val_accuracy: 0.6861\n",
      "Epoch 24/30\n",
      "62/62 [==============================] - 53s 849ms/step - loss: 0.5748 - accuracy: 0.7072 - val_loss: 0.5552 - val_accuracy: 0.7042\n",
      "Epoch 25/30\n",
      "62/62 [==============================] - 54s 863ms/step - loss: 0.5819 - accuracy: 0.7006 - val_loss: 0.5492 - val_accuracy: 0.7103\n",
      "Epoch 26/30\n",
      "62/62 [==============================] - 53s 852ms/step - loss: 0.5698 - accuracy: 0.6915 - val_loss: 0.5481 - val_accuracy: 0.7183\n",
      "Epoch 27/30\n",
      "62/62 [==============================] - 53s 847ms/step - loss: 0.5861 - accuracy: 0.6910 - val_loss: 0.5974 - val_accuracy: 0.6700\n",
      "Epoch 28/30\n",
      "62/62 [==============================] - 54s 866ms/step - loss: 0.5672 - accuracy: 0.7046 - val_loss: 0.5444 - val_accuracy: 0.6962\n",
      "Epoch 29/30\n",
      "62/62 [==============================] - 55s 879ms/step - loss: 0.5685 - accuracy: 0.7046 - val_loss: 0.5575 - val_accuracy: 0.7022\n",
      "Epoch 30/30\n",
      "62/62 [==============================] - 55s 889ms/step - loss: 0.5671 - accuracy: 0.7021 - val_loss: 0.5439 - val_accuracy: 0.7304\n"
     ]
    }
   ],
   "source": [
    "tensorboard_resnet50 = TensorBoard(log_dir='logs/resnet50')\n",
    "callbacks = [tensorboard_resnet50]\n",
    "model_resnet50.fit(train_generator,\n",
    "                   epochs=N_EPOCHS,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=validation_generator)\n",
    "model_resnet50.save(os.path.join(WEIGHTS_DIR, \"model_resnet50.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "62/62 [==============================] - 33s 480ms/step - loss: 0.5368 - accuracy: 0.7223 - val_loss: 0.4012 - val_accuracy: 0.8089\n",
      "Epoch 2/30\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.3650 - accuracy: 0.8438 - val_loss: 0.3585 - val_accuracy: 0.8249\n",
      "Epoch 3/30\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.3456 - accuracy: 0.8478 - val_loss: 0.3242 - val_accuracy: 0.8491\n",
      "Epoch 4/30\n",
      "62/62 [==============================] - 28s 459ms/step - loss: 0.2953 - accuracy: 0.8740 - val_loss: 0.2872 - val_accuracy: 0.8793\n",
      "Epoch 5/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.2830 - accuracy: 0.8816 - val_loss: 0.2884 - val_accuracy: 0.8773\n",
      "Epoch 6/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.2683 - accuracy: 0.8906 - val_loss: 0.2661 - val_accuracy: 0.8913\n",
      "Epoch 7/30\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2426 - accuracy: 0.9057 - val_loss: 0.3326 - val_accuracy: 0.8531\n",
      "Epoch 8/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.2368 - accuracy: 0.9027 - val_loss: 0.3229 - val_accuracy: 0.8471\n",
      "Epoch 9/30\n",
      "62/62 [==============================] - 28s 454ms/step - loss: 0.2309 - accuracy: 0.8997 - val_loss: 0.2667 - val_accuracy: 0.8773\n",
      "Epoch 10/30\n",
      "62/62 [==============================] - 28s 456ms/step - loss: 0.2275 - accuracy: 0.9083 - val_loss: 0.2426 - val_accuracy: 0.8873\n",
      "Epoch 11/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.2058 - accuracy: 0.9194 - val_loss: 0.4179 - val_accuracy: 0.8209\n",
      "Epoch 12/30\n",
      "62/62 [==============================] - 28s 455ms/step - loss: 0.2057 - accuracy: 0.9194 - val_loss: 0.2529 - val_accuracy: 0.8893\n",
      "Epoch 13/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.1905 - accuracy: 0.9294 - val_loss: 0.2471 - val_accuracy: 0.8873\n",
      "Epoch 14/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.1868 - accuracy: 0.9294 - val_loss: 0.2757 - val_accuracy: 0.8893\n",
      "Epoch 15/30\n",
      "62/62 [==============================] - 28s 454ms/step - loss: 0.1887 - accuracy: 0.9299 - val_loss: 0.2615 - val_accuracy: 0.8893\n",
      "Epoch 16/30\n",
      "62/62 [==============================] - 28s 456ms/step - loss: 0.1786 - accuracy: 0.9249 - val_loss: 0.1946 - val_accuracy: 0.9235\n",
      "Epoch 17/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.1715 - accuracy: 0.9340 - val_loss: 0.2509 - val_accuracy: 0.8934\n",
      "Epoch 18/30\n",
      "62/62 [==============================] - 28s 455ms/step - loss: 0.1700 - accuracy: 0.9375 - val_loss: 0.2198 - val_accuracy: 0.9054\n",
      "Epoch 19/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.1634 - accuracy: 0.9360 - val_loss: 0.1874 - val_accuracy: 0.9215\n",
      "Epoch 20/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.1494 - accuracy: 0.9471 - val_loss: 0.2122 - val_accuracy: 0.9054\n",
      "Epoch 21/30\n",
      "62/62 [==============================] - 28s 455ms/step - loss: 0.1534 - accuracy: 0.9410 - val_loss: 0.1851 - val_accuracy: 0.9215\n",
      "Epoch 22/30\n",
      "62/62 [==============================] - 28s 459ms/step - loss: 0.1446 - accuracy: 0.9451 - val_loss: 0.2113 - val_accuracy: 0.9135\n",
      "Epoch 23/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.1557 - accuracy: 0.9365 - val_loss: 0.2302 - val_accuracy: 0.9054\n",
      "Epoch 24/30\n",
      "62/62 [==============================] - 28s 455ms/step - loss: 0.1431 - accuracy: 0.9471 - val_loss: 0.1732 - val_accuracy: 0.9276\n",
      "Epoch 25/30\n",
      "62/62 [==============================] - 28s 458ms/step - loss: 0.1555 - accuracy: 0.9390 - val_loss: 0.1831 - val_accuracy: 0.9235\n",
      "Epoch 26/30\n",
      "62/62 [==============================] - 28s 459ms/step - loss: 0.1286 - accuracy: 0.9551 - val_loss: 0.2141 - val_accuracy: 0.9095\n",
      "Epoch 27/30\n",
      "62/62 [==============================] - 28s 454ms/step - loss: 0.1266 - accuracy: 0.9587 - val_loss: 0.1754 - val_accuracy: 0.9296\n",
      "Epoch 28/30\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.1372 - accuracy: 0.9476 - val_loss: 0.1543 - val_accuracy: 0.9356\n",
      "Epoch 29/30\n",
      "62/62 [==============================] - 28s 456ms/step - loss: 0.1158 - accuracy: 0.9587 - val_loss: 0.1584 - val_accuracy: 0.9356\n",
      "Epoch 30/30\n",
      "62/62 [==============================] - 28s 456ms/step - loss: 0.1142 - accuracy: 0.9607 - val_loss: 0.1799 - val_accuracy: 0.9276\n"
     ]
    }
   ],
   "source": [
    "tensorboard_mobilenetv2 = TensorBoard(log_dir='logs/mobilenetv2')\n",
    "callbacks = [tensorboard_mobilenetv2]\n",
    "model_mobilenetv2.fit(train_generator,\n",
    "                      epochs=N_EPOCHS,\n",
    "                      callbacks=callbacks,\n",
    "                      validation_data=validation_generator)\n",
    "model_mobilenetv2.save(os.path.join(WEIGHTS_DIR, \"model_mobilenetv2.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "62/62 [==============================] - 73s 977ms/step - loss: 0.5995 - accuracy: 0.6820 - val_loss: 0.6036 - val_accuracy: 0.6942\n",
      "Epoch 2/30\n",
      "62/62 [==============================] - 58s 931ms/step - loss: 0.4582 - accuracy: 0.7777 - val_loss: 0.4108 - val_accuracy: 0.8068\n",
      "Epoch 3/30\n",
      "62/62 [==============================] - 57s 910ms/step - loss: 0.4370 - accuracy: 0.7959 - val_loss: 0.4115 - val_accuracy: 0.8048\n",
      "Epoch 4/30\n",
      "62/62 [==============================] - 57s 911ms/step - loss: 0.4381 - accuracy: 0.7888 - val_loss: 0.4684 - val_accuracy: 0.7807\n",
      "Epoch 5/30\n",
      "62/62 [==============================] - 57s 924ms/step - loss: 0.4036 - accuracy: 0.8135 - val_loss: 0.3732 - val_accuracy: 0.8310\n",
      "Epoch 6/30\n",
      "62/62 [==============================] - 57s 912ms/step - loss: 0.3683 - accuracy: 0.8362 - val_loss: 0.3654 - val_accuracy: 0.8310\n",
      "Epoch 7/30\n",
      "62/62 [==============================] - 62s 1s/step - loss: 0.3759 - accuracy: 0.8266 - val_loss: 0.3891 - val_accuracy: 0.8068\n",
      "Epoch 8/30\n",
      "62/62 [==============================] - 61s 977ms/step - loss: 0.3541 - accuracy: 0.8483 - val_loss: 0.3507 - val_accuracy: 0.8290\n",
      "Epoch 9/30\n",
      "62/62 [==============================] - 57s 917ms/step - loss: 0.3811 - accuracy: 0.8301 - val_loss: 0.3747 - val_accuracy: 0.8451\n",
      "Epoch 10/30\n",
      "62/62 [==============================] - 57s 919ms/step - loss: 0.3390 - accuracy: 0.8498 - val_loss: 0.3485 - val_accuracy: 0.8431\n",
      "Epoch 11/30\n",
      "62/62 [==============================] - 58s 929ms/step - loss: 0.3387 - accuracy: 0.8518 - val_loss: 0.3338 - val_accuracy: 0.8612\n",
      "Epoch 12/30\n",
      "62/62 [==============================] - 58s 927ms/step - loss: 0.3153 - accuracy: 0.8690 - val_loss: 0.3324 - val_accuracy: 0.8672\n",
      "Epoch 13/30\n",
      "62/62 [==============================] - 57s 917ms/step - loss: 0.3167 - accuracy: 0.8619 - val_loss: 0.3154 - val_accuracy: 0.8612\n",
      "Epoch 14/30\n",
      "62/62 [==============================] - 58s 927ms/step - loss: 0.3154 - accuracy: 0.8614 - val_loss: 0.3429 - val_accuracy: 0.8330\n",
      "Epoch 15/30\n",
      "62/62 [==============================] - 57s 917ms/step - loss: 0.3038 - accuracy: 0.8715 - val_loss: 0.3028 - val_accuracy: 0.8732\n",
      "Epoch 16/30\n",
      "62/62 [==============================] - 57s 924ms/step - loss: 0.2876 - accuracy: 0.8775 - val_loss: 0.2913 - val_accuracy: 0.8712\n",
      "Epoch 17/30\n",
      "62/62 [==============================] - 59s 955ms/step - loss: 0.3091 - accuracy: 0.8533 - val_loss: 0.3025 - val_accuracy: 0.8592\n",
      "Epoch 18/30\n",
      "62/62 [==============================] - 59s 952ms/step - loss: 0.3101 - accuracy: 0.8599 - val_loss: 0.3741 - val_accuracy: 0.8451\n",
      "Epoch 19/30\n",
      "62/62 [==============================] - 58s 930ms/step - loss: 0.2976 - accuracy: 0.8740 - val_loss: 0.2868 - val_accuracy: 0.8893\n",
      "Epoch 20/30\n",
      "62/62 [==============================] - 58s 934ms/step - loss: 0.2971 - accuracy: 0.8730 - val_loss: 0.2975 - val_accuracy: 0.8592\n",
      "Epoch 21/30\n",
      "62/62 [==============================] - 59s 958ms/step - loss: 0.2725 - accuracy: 0.8891 - val_loss: 0.3075 - val_accuracy: 0.8511\n",
      "Epoch 22/30\n",
      "62/62 [==============================] - 58s 938ms/step - loss: 0.2683 - accuracy: 0.8931 - val_loss: 0.3533 - val_accuracy: 0.8551\n",
      "Epoch 23/30\n",
      "62/62 [==============================] - 59s 942ms/step - loss: 0.2769 - accuracy: 0.8861 - val_loss: 0.2909 - val_accuracy: 0.8632\n",
      "Epoch 24/30\n",
      "62/62 [==============================] - 58s 931ms/step - loss: 0.2898 - accuracy: 0.8800 - val_loss: 0.3853 - val_accuracy: 0.8270\n",
      "Epoch 25/30\n",
      "62/62 [==============================] - 58s 934ms/step - loss: 0.2653 - accuracy: 0.8916 - val_loss: 0.2690 - val_accuracy: 0.8994\n",
      "Epoch 26/30\n",
      "62/62 [==============================] - 59s 943ms/step - loss: 0.2556 - accuracy: 0.8962 - val_loss: 0.2897 - val_accuracy: 0.8652\n",
      "Epoch 27/30\n",
      "62/62 [==============================] - 59s 950ms/step - loss: 0.2610 - accuracy: 0.8906 - val_loss: 0.2641 - val_accuracy: 0.8873\n",
      "Epoch 28/30\n",
      "62/62 [==============================] - 58s 932ms/step - loss: 0.2475 - accuracy: 0.8967 - val_loss: 0.2663 - val_accuracy: 0.9014\n",
      "Epoch 29/30\n",
      "62/62 [==============================] - 57s 923ms/step - loss: 0.2525 - accuracy: 0.8921 - val_loss: 0.3170 - val_accuracy: 0.8753\n",
      "Epoch 30/30\n",
      "62/62 [==============================] - 57s 924ms/step - loss: 0.2673 - accuracy: 0.8906 - val_loss: 0.2711 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "tensorboard_inception_resnet_v2 = TensorBoard(\n",
    "    log_dir='logs/inception_resnet_v2')\n",
    "callbacks = [tensorboard_inception_resnet_v2]\n",
    "model_inception_resnet_v2.fit(train_generator,\n",
    "                              epochs=N_EPOCHS,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=validation_generator)\n",
    "model_inception_resnet_v2.save(os.path.join(\n",
    "    WEIGHTS_DIR, \"model_inception_resnet_v2.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5789da37b6814a2c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5789da37b6814a2c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
